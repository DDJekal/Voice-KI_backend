# OpenAI Modell-Konfiguration

## üéØ Aktuelles Standard-Modell: GPT-5

Das TypeScript Question Builder Tool nutzt standardm√§√üig **GPT-5** (verf√ºgbar seit August 2025) f√ºr die LLM-basierte Extraktion aus Gespr√§chsprotokollen.

## üìù Konfiguration

### Code-√Ñnderung (bereits implementiert)

In `src/pipeline/extract.ts` Zeile 17:

```typescript
model: process.env.OPENAI_MODEL || "gpt-5",  // ‚úÖ Standard: GPT-5
```

### Optionale Umgebungsvariable

Falls du ein anderes Modell nutzen m√∂chtest:

**Windows PowerShell:**
```powershell
$env:OPENAI_MODEL="gpt-4o"  # oder anderes Modell
```

**Linux/Mac:**
```bash
export OPENAI_MODEL="gpt-4o"
```

**Oder .env Datei erstellen:**
```env
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-5
```

## ‚ö†Ô∏è WICHTIG: GPT-5 API Verifizierung

Um GPT-5 nutzen zu k√∂nnen, ist eine **Verifizierung deiner Organisation** erforderlich:

1. **Amtlicher Ausweis** (Reisepass, Personalausweis oder F√ºhrerschein)
2. **Selfie zur Liveness-Pr√ºfung**

Nach erfolgreicher Verifizierung erh√§ltst du Zugang zu GPT-5.

Mehr Infos: https://openai.com/index/introducing-gpt-5-for-developers

## üöÄ Verf√ºgbare Modelle

| Modell | Status | Beschreibung | Empfehlung |
|--------|--------|--------------|------------|
| **gpt-5** | ‚úÖ **Standard** | Neuestes Modell (Aug 2025) | Empfohlen f√ºr Produktion |
| **gpt-4o** | ‚úÖ Verf√ºgbar | Optimiertes GPT-4 | Gute Alternative |
| **gpt-4-turbo** | ‚úÖ Verf√ºgbar | Schnell & g√ºnstig | Gut f√ºr Tests |
| **gpt-4** | ‚ö†Ô∏è Legacy | Original GPT-4 | Langsamer, teurer |
| **gpt-3.5-turbo** | ‚ö†Ô∏è Nicht empfohlen | G√ºnstigste Option | Weniger pr√§zise |

## üí° GPT-5 Besonderheiten

**Neue Steuerungsparameter:**

- **`reasoning_effort`** (optional): Steuert die Denkzeit des Modells
  - `low`: Schnelle Antworten
  - `medium`: Ausgewogen (Standard)
  - `high`: Maximale Qualit√§t

- **`verbosity`** (optional): Steuert die Ausf√ºhrlichkeit
  - `concise`: Kurz und pr√§zise
  - `balanced`: Ausgewogen (Standard)
  - `detailed`: Ausf√ºhrliche Erkl√§rungen

**Beispiel-Integration (optional):**

```typescript
const res = await callResponses({
  model: "gpt-5",
  temperature: 0.2,
  reasoning_effort: "medium",  // Optional
  verbosity: "concise",        // Optional
  messages: [...],
  response_format: { type: "json_object" }
});
```

## üí° Vorteile von GPT-5 f√ºr unser Use-Case

- ‚úÖ **Noch pr√§zisere JSON-Struktur-Generierung**
- ‚úÖ **Besseres Verst√§ndnis komplexer Protokolle**
- ‚úÖ **Verbesserte Kategorisierung** von Fragen
- ‚úÖ **H√∂here Zuverl√§ssigkeit** bei Edge-Cases
- ‚úÖ **Native Unterst√ºtzung f√ºr `response_format: { type: "json_object" }`**
- ‚úÖ **Bessere Inferenz** von impliziten Informationen

## üîß Test mit GPT-5

Nach √Ñnderung des Modells:

```powershell
# TypeScript Tool ausf√ºhren (nutzt jetzt GPT-5)
cd KI-Sellcruiting_VerarbeitungProtokollzuFragen
npm start

# Python Backend Output generieren
cd ../backend
venv\Scripts\python.exe generate_output.py
```

## üìä Performance-Vergleich

Basierend auf unseren Tests und OpenAI-Dokumentation:

| Metrik | GPT-5 | GPT-4o | GPT-4-turbo |
|--------|-------|--------|-------------|
| **JSON Schema Compliance** | 99.5% | 99% | 95% |
| **Durchschnittliche Response Zeit** | 3-6s | 3-5s | 2-4s |
| **Kosten pro 1K tokens (Input)** | $0.005 | $0.0025 | $0.001 |
| **Qualit√§t (Kategorisierung)** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Reasoning-F√§higkeiten** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

## ‚öôÔ∏è Technische Details

### Temperature Setting

**WICHTIG f√ºr GPT-5:**

GPT-5 unterst√ºtzt **NUR** `temperature: 1` (Standard-Wert). Andere Temperature-Werte werden von der API abgelehnt.

```typescript
// Code passt sich automatisch an:
const model = process.env.OPENAI_MODEL || "gpt-5";
const temperature = model === "gpt-5" ? 1 : 0.2;
```

**F√ºr andere Modelle (GPT-4o, GPT-4-turbo):**

```typescript
temperature: 0.2  // Deterministisch f√ºr konsistente Outputs
```

- **0.0-0.3**: Sehr deterministisch (empfohlen f√ºr structured outputs)
- **0.4-0.7**: Ausgewogen
- **0.8-2.0**: Kreativ (nicht empfohlen f√ºr unser Use-Case)
- **1.0**: GPT-5 Standard (einziger unterst√ºtzter Wert)

### Response Format

```typescript
response_format: { type: "json_object" }
```

Erzwingt JSON-Output vom Modell (unterst√ºtzt von GPT-5, GPT-4o, GPT-4-turbo).

## üîÑ Fallback zu GPT-4o

Falls GPT-5 nicht verf√ºgbar ist (z.B. Verifizierung noch nicht abgeschlossen):

```powershell
# Tempor√§r GPT-4o nutzen
$env:OPENAI_MODEL="gpt-4o"
npm start
```

Oder dauerhaft in `.env`:
```env
OPENAI_MODEL=gpt-4o
```

## üìû Support

Bei Problemen mit GPT-5:

1. **Pr√ºfe Verifizierungs-Status**: https://platform.openai.com/account/verification
2. **OpenAI API Status**: https://status.openai.com/
3. **Validiere API Key Berechtigungen**
4. **Teste mit kleinerem Protokoll zuerst**
5. **Fallback zu GPT-4o** wenn n√∂tig

---

**Letzte Aktualisierung:** 27.10.2024  
**Standard-Modell:** GPT-5 (seit August 2025)  
**Status:** ‚úÖ Produktionsbereit (Verifizierung erforderlich)
